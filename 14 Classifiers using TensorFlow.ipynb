{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load IMDB tfidf data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.776831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.789451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.763420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.829025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.817180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1    2    3       4    5        6    7    8    9    ...      \\\n",
       "0  0.776831  0.0  0.0  0.0  0.0155  0.0  0.01595  0.0  0.0  0.0    ...       \n",
       "1  0.789451  0.0  0.0  0.0  0.0000  0.0  0.00000  0.0  0.0  0.0    ...       \n",
       "2  0.763420  0.0  0.0  0.0  0.0000  0.0  0.00000  0.0  0.0  0.0    ...       \n",
       "3  0.829025  0.0  0.0  0.0  0.0000  0.0  0.00000  0.0  0.0  0.0    ...       \n",
       "4  0.817180  0.0  0.0  0.0  0.0000  0.0  0.00000  0.0  0.0  0.0    ...       \n",
       "\n",
       "    59   60   61   62   63   64   65   66   67  sentiment  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0          1  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0          1  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0          1  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0          1  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0          1  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"data/imdb/train.csv\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.iloc[:, :-1].values\n",
    "y_train = df_train.sentiment.values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.808599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.788513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.768390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.816795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.771710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010539</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1         2    3         4    5    6    7    8    9    ...      \\\n",
       "0  0.808599  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  0.0    ...       \n",
       "1  0.788513  0.0  0.008864  0.0  0.006284  0.0  0.0  0.0  0.0  0.0    ...       \n",
       "2  0.768390  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  0.0    ...       \n",
       "3  0.816795  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  0.0    ...       \n",
       "4  0.771710  0.0  0.014865  0.0  0.010539  0.0  0.0  0.0  0.0  0.0    ...       \n",
       "\n",
       "    59   60   61   62   63   64   65   66   67  sentiment  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0          1  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0          1  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0          1  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0          1  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0          1  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"data/imdb/test.csv\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = df_test.iloc[:, :-1].values\n",
    "y_test = df_test.sentiment.values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Logistic Regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.61476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7941, 4559],\n",
       "       [5072, 7428]])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "lr = LogisticRegression(C=1, random_state=1)\n",
    "lr.fit(X_train_std, y_train)\n",
    "y_test_pred = lr.predict(X_test_std)\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_test_pred))\n",
    "confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.71279154, -0.03989314, -0.00945179, -0.05862788, -0.12234314,\n",
       "        -0.04317324, -0.0152893 ,  0.02652596,  0.08176166,  0.08939853,\n",
       "         0.05202108, -0.03179782, -0.25265378, -0.04101148, -0.44233956,\n",
       "         0.09978523, -0.06799937, -0.17086883,  0.10906907, -0.15115334,\n",
       "         0.00384509, -0.19009448, -0.21940036,  0.03598855, -0.05612759,\n",
       "        -0.19516636, -0.03242399, -0.08557588,  0.0203025 ,  0.06574934,\n",
       "         0.0483843 , -0.05347545, -0.03038236, -0.04955422, -0.00404738,\n",
       "         0.01646328, -0.02550116, -0.01609564,  0.10755131,  0.00847538,\n",
       "        -0.00293419,  0.10394609,  0.01345728,  0.02753872, -0.07293686,\n",
       "         0.03101284, -0.0165269 , -0.01719957,  0.04025995, -0.00439755,\n",
       "         0.01630796, -0.0869459 , -0.00077606,  0.08809349, -0.01037629,\n",
       "         0.01744801, -0.0220454 ,  0.03226595,  0.00429942, -0.14439276,\n",
       "        -0.01580498, -0.17110365, -0.02108478,  0.11651601,  0.04969867,\n",
       "        -0.05768173, -0.05024891,  0.05170648]])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batchable:\n",
    "\n",
    "    def __init__(self, X, y, batch_size = 256, seed = None):\n",
    "        import math\n",
    "        import numpy as np\n",
    "        if seed:\n",
    "            np.random.seed(seed)\n",
    "        idx = np.arange(X.shape[1])\n",
    "        np.random.shuffle(idx)\n",
    "        self.X = X[:, idx]\n",
    "        self.y = y[:, idx]\n",
    "        self.start = 0\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches = math.ceil(X.shape[0] / batch_size)\n",
    "    \n",
    "    def next(self):\n",
    "        end = self.start + self.batch_size\n",
    "        if end > self.X.shape[1]:\n",
    "            end = self.X.shape[1] - 1\n",
    "        return self.X[:, self.start: (end + 1)], self.y[:, self.start: (end + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cost': 0.87126076, 'training accuracy': 0.50583655}\n",
      "{'cost': 0.65061682, 'training accuracy': 0.66147858}\n",
      "{'cost': 0.66520262, 'training accuracy': 0.61089492}\n",
      "{'cost': 0.67054105, 'training accuracy': 0.59143966}\n",
      "{'cost': 0.63096231, 'training accuracy': 0.63035017}\n",
      "{'cost': 0.63412017, 'training accuracy': 0.62256807}\n",
      "{'cost': 0.6975162, 'training accuracy': 0.56031126}\n",
      "{'cost': 0.64336205, 'training accuracy': 0.64202332}\n",
      "{'cost': 0.65301967, 'training accuracy': 0.61867702}\n",
      "{'cost': 0.67494446, 'training accuracy': 0.53696495}\n",
      "{'cost': 0.68239218, 'training accuracy': 0.54863811}\n",
      "Test accuracy 0.61256\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "    \n",
    "def binary_classification(X_train, y_train, X_test, y_test):\n",
    "    learning_rate = 0.01\n",
    "    epochs = 1000\n",
    "    n_x, m = X_train.shape\n",
    "\n",
    "    X = tf.placeholder(dtype=tf.float32, shape = [n_x, None], name=\"X\")\n",
    "    y = tf.placeholder(dtype=tf.float32, shape = [1, None], name=\"y\")\n",
    "    \n",
    "    threshold = tf.constant(0.5)\n",
    "\n",
    "    n_h = 5\n",
    "\n",
    "    W1 = tf.get_variable(\"W1\", [1, n_x], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [1,1], initializer = tf.zeros_initializer())\n",
    "\n",
    "    Z1 = tf.matmul(W1, X) + b1\n",
    "    #A1 = tf.nn.tanh(Z1)\n",
    "\n",
    "    #W2 = tf.get_variable(\"W2\", [1, n_h], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    #b2 = tf.get_variable(\"b2\", [1,1], initializer = tf.zeros_initializer())\n",
    "\n",
    "    #Z2 = tf.matmul(W2, A1) + b2\n",
    "    AL = tf.nn.sigmoid(Z1)\n",
    "\n",
    "\n",
    "    y_pred = tf.where(AL > threshold, tf.ones_like(AL), tf.zeros_like(AL))\n",
    "\n",
    "    correct_prediction = tf.equal(y, y_pred)\n",
    "\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    regularizer = tf.nn.l2_loss(W1)\n",
    "\n",
    "    cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=Z1))\n",
    "\n",
    "    training = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    costs = []\n",
    "\n",
    "    with tf.Session() as session:\n",
    "        session.run(init)\n",
    "        for epoch in range(epochs):\n",
    "            batchable = Batchable(X_train, y_train)\n",
    "            for i in range(batchable.num_batches):\n",
    "                X_data, y_data = batchable.next()\n",
    "                _, training_cost_, accuracy_ = session.run([training, cost, accuracy], feed_dict = {X: X_data, y: y_data})\n",
    "                costs.append(training_cost_)\n",
    "            if epoch % 100 == 0 or epoch == epochs-1:\n",
    "                print({\"cost\": training_cost_, \"training accuracy\": accuracy_})\n",
    "                \n",
    "        test_accuracy = session.run(accuracy, feed_dict = {X: X_test, y: y_test})\n",
    "        print(\"Test accuracy\", test_accuracy)\n",
    "        \n",
    "binary_classification(X_train_std.T, y_train.reshape(1, -1), X_test_std.T, y_test.reshape(1, -1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Class Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/MNIST/mnist_train.csv\", header= None)\n",
    "y_train = df_train.iloc[:, 0]\n",
    "X_train = df_train.iloc[:, 1:].values/255\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "y_train = ohe.fit_transform(y_train.values.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"data/MNIST/mnist_test.csv\", header=None)\n",
    "y_test = df_test.iloc[:, 0]\n",
    "X_test = df_test.iloc[:, 1:].values/255\n",
    "X_test_std = scaler.fit_transform(X_test)\n",
    "y_test = ohe.fit_transform(y_test.values.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 60000), (10, 10000))"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'cost': 0.65078586}\n",
      "{'epoch': 100, 'cost': 0.57446724}\n",
      "{'epoch': 200, 'cost': 0.55498886}\n",
      "{'epoch': 300, 'cost': 0.58173239}\n",
      "{'epoch': 400, 'cost': 0.53572977}\n",
      "{'epoch': 499, 'cost': 0.50085109}\n",
      "Train Accuracy: 0.8055\n",
      "Test Accuracy: 0.5365\n",
      "Total time taken:  1717.75910115242\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "def multi_layer(X_train, y_train, X_test, y_test, learning_rate= 0.001, epochs = 1000):\n",
    "    \n",
    "    n_x, m = X_train.shape\n",
    "    n_y = 10\n",
    "    X = tf.placeholder(dtype=tf.float32, shape=[n_x, None], name = \"X\")\n",
    "    Y = tf.placeholder(dtype=tf.float32, shape=[n_y, None], name = \"Y\")\n",
    "    tf.set_random_seed(1)\n",
    "    \n",
    "    layers = [n_x, 100, 20, n_y]\n",
    "    num_layers = len(layers) - 1\n",
    "    \n",
    "    parameters = {}\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "        W = tf.get_variable(\"W\"+str(i), shape = [layers[i+1], layers[i]], \n",
    "                            initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "        b = tf.get_variable(\"b\" + str(i), [layers[i+1], 1], initializer = tf.zeros_initializer())\n",
    "        parameters[\"W\"+str(i)] = W\n",
    "        parameters[\"b\"+str(i)] = b\n",
    "    \n",
    "    A = X\n",
    "    for i in range(num_layers):\n",
    "        W = parameters[\"W\"+str(i)]\n",
    "        b = parameters[\"b\"+str(i)]\n",
    "        Z = tf.matmul(W, A) + b\n",
    "        A = tf.nn.tanh(Z) if i < num_layers - 1 else tf.nn.softmax(Z)\n",
    "    \n",
    "    logits = tf.transpose(Z)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    costs = []\n",
    "    with tf.Session() as session:\n",
    "        session.run(init)\n",
    "        for epoch in range(epochs):\n",
    "            batchable = Batchable(X_train, y_train)\n",
    "            for i in range(batchable.num_batches):\n",
    "                X_data, y_data = batchable.next()\n",
    "                _, cost_ = session.run([optimizer, cost], feed_dict={X: X_data, Y: y_data})\n",
    "                costs.append(cost_)\n",
    "            \n",
    "            if epoch % 100 == 0 or epoch == epochs-1:\n",
    "                print({\"epoch\": epoch, \"cost\": cost_})\n",
    "                \n",
    "        correct_prediction = tf.equal(tf.argmax(Z), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: y_test}))\n",
    "\n",
    "start_time = time()\n",
    "multi_layer(X_train_std.T, y_train.T, X_test.T, y_test.T, learning_rate=0.1, epochs=500)\n",
    "print(\"Total time taken: \", time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
