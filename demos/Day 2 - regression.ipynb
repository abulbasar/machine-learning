{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31</td>\n",
       "      <td>female</td>\n",
       "      <td>25.740</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>3756.62160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>46</td>\n",
       "      <td>female</td>\n",
       "      <td>33.440</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>8240.58960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37</td>\n",
       "      <td>female</td>\n",
       "      <td>27.740</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>7281.50560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>37</td>\n",
       "      <td>male</td>\n",
       "      <td>29.830</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>6406.41070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60</td>\n",
       "      <td>female</td>\n",
       "      <td>25.840</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>28923.13692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  gender     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520\n",
       "5   31  female  25.740         0     no  southeast   3756.62160\n",
       "6   46  female  33.440         1     no  southeast   8240.58960\n",
       "7   37  female  27.740         3     no  northwest   7281.50560\n",
       "8   37    male  29.830         2     no  northeast   6406.41070\n",
       "9   60  female  25.840         0     no  northwest  28923.13692"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/data/insurance.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training: 0.6995515695067265\n"
     ]
    }
   ],
   "source": [
    "# dependent variable/target varible/label\n",
    "label = \"charges\"\n",
    "\n",
    "# independepent variables/features/predictors\n",
    "X = df.drop(columns=[label])\n",
    "\n",
    "# vector for target variable\n",
    "y = df[label]\n",
    "\n",
    "# one hot encoding to conver categorical features into numeric\n",
    "# drop_first: remove first categorical feature ... it is redundant\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Creating trainnig and test sets\n",
    "# test_size is 30% of the whole\n",
    "# random_state: to reprduce the same combination of training and test records\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X.values, \n",
    "                                                                    \n",
    "                                                                    y, test_size = 0.3\n",
    "                                                        , random_state = 1)\n",
    "\n",
    "print(\"size of training:\", len(X_train)/len(X))\n",
    "\n",
    "# We want to calcualate z score for each column \n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# We calcualte mean and std dev for each column\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Calculating the z scores\n",
    "# purpose of z scoring is make mean = 0 and std = 1 for each column\n",
    "X_train_std = scaler.transform(X_train)\n",
    "\n",
    "# Displaying the mean and standard deviation of the stadandarized features\n",
    "pd.DataFrame(X_train_std).describe()\n",
    "\n",
    "# Applying the same transformation on the test data\n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "# building a regression model\n",
    "est = linear_model.LinearRegression()\n",
    "est.fit(X_train_std, y_train)\n",
    "\n",
    "# prediction on training and test data\n",
    "y_train_pred = est.predict(X_train_std)\n",
    "y_test_pred = est.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>prediction</th>\n",
       "      <th>residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>1646.42970</td>\n",
       "      <td>4610.315541</td>\n",
       "      <td>2963.885841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>11353.22760</td>\n",
       "      <td>12887.893880</td>\n",
       "      <td>1534.666280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>8798.59300</td>\n",
       "      <td>12573.948752</td>\n",
       "      <td>3775.355752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>10381.47870</td>\n",
       "      <td>13197.836626</td>\n",
       "      <td>2816.357926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>2103.08000</td>\n",
       "      <td>629.337182</td>\n",
       "      <td>-1473.742818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>38746.35510</td>\n",
       "      <td>32357.257584</td>\n",
       "      <td>-6389.097516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>9304.70190</td>\n",
       "      <td>12853.778438</td>\n",
       "      <td>3549.076538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>11658.11505</td>\n",
       "      <td>12273.662540</td>\n",
       "      <td>615.547490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>3070.80870</td>\n",
       "      <td>3865.164045</td>\n",
       "      <td>794.355345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>19539.24300</td>\n",
       "      <td>29904.111392</td>\n",
       "      <td>10364.868392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>12629.89670</td>\n",
       "      <td>11030.536184</td>\n",
       "      <td>-1599.360516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>11538.42100</td>\n",
       "      <td>17428.893541</td>\n",
       "      <td>5890.472541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>6338.07560</td>\n",
       "      <td>8670.208104</td>\n",
       "      <td>2332.132504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>7050.64200</td>\n",
       "      <td>8357.459712</td>\n",
       "      <td>1306.817712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1137.46970</td>\n",
       "      <td>3368.753659</td>\n",
       "      <td>2231.283959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>8968.33000</td>\n",
       "      <td>10316.585740</td>\n",
       "      <td>1348.255740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21984.47061</td>\n",
       "      <td>3999.221358</td>\n",
       "      <td>-17985.249252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>6414.17800</td>\n",
       "      <td>6866.509328</td>\n",
       "      <td>452.331328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>28287.89766</td>\n",
       "      <td>14989.263965</td>\n",
       "      <td>-13298.633695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>13462.52000</td>\n",
       "      <td>14400.167009</td>\n",
       "      <td>937.647009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>9722.76950</td>\n",
       "      <td>12484.860025</td>\n",
       "      <td>2762.090525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>40932.42950</td>\n",
       "      <td>33255.453304</td>\n",
       "      <td>-7676.976196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>8026.66660</td>\n",
       "      <td>9177.111104</td>\n",
       "      <td>1150.444504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>8444.47400</td>\n",
       "      <td>8969.420175</td>\n",
       "      <td>524.946175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>2203.47185</td>\n",
       "      <td>3199.783106</td>\n",
       "      <td>996.311256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>6664.68595</td>\n",
       "      <td>8195.258443</td>\n",
       "      <td>1530.572493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>8606.21740</td>\n",
       "      <td>9355.744165</td>\n",
       "      <td>749.526765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>8283.68070</td>\n",
       "      <td>10847.377942</td>\n",
       "      <td>2563.697242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>5375.03800</td>\n",
       "      <td>7694.604698</td>\n",
       "      <td>2319.566698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>3645.08940</td>\n",
       "      <td>4436.447849</td>\n",
       "      <td>791.358449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>5699.83750</td>\n",
       "      <td>8873.734143</td>\n",
       "      <td>3173.896643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>25656.57526</td>\n",
       "      <td>10365.420802</td>\n",
       "      <td>-15291.154458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>6652.52880</td>\n",
       "      <td>5146.284716</td>\n",
       "      <td>-1506.244084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>10269.46000</td>\n",
       "      <td>12154.347446</td>\n",
       "      <td>1884.887446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>15019.76005</td>\n",
       "      <td>14782.131446</td>\n",
       "      <td>-237.628604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>2741.94800</td>\n",
       "      <td>4298.391463</td>\n",
       "      <td>1556.443463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>6435.62370</td>\n",
       "      <td>13086.510055</td>\n",
       "      <td>6650.886355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>11938.25595</td>\n",
       "      <td>13045.515296</td>\n",
       "      <td>1107.259346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>7261.74100</td>\n",
       "      <td>10408.467573</td>\n",
       "      <td>3146.726573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>17496.30600</td>\n",
       "      <td>28136.555213</td>\n",
       "      <td>10640.249213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>33307.55080</td>\n",
       "      <td>27176.138386</td>\n",
       "      <td>-6131.412414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>32787.45859</td>\n",
       "      <td>33165.632331</td>\n",
       "      <td>378.173741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>28468.91901</td>\n",
       "      <td>12621.577467</td>\n",
       "      <td>-15847.341543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>20462.99766</td>\n",
       "      <td>14665.580509</td>\n",
       "      <td>-5797.417151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>12574.04900</td>\n",
       "      <td>17154.057687</td>\n",
       "      <td>4580.008687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>3736.46470</td>\n",
       "      <td>4347.234024</td>\n",
       "      <td>610.769324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>4795.65680</td>\n",
       "      <td>9509.419524</td>\n",
       "      <td>4713.762724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>12032.32600</td>\n",
       "      <td>9263.424639</td>\n",
       "      <td>-2768.901361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>37742.57570</td>\n",
       "      <td>31958.417709</td>\n",
       "      <td>-5784.157991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>46718.16325</td>\n",
       "      <td>39026.197693</td>\n",
       "      <td>-7691.965557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>8334.45755</td>\n",
       "      <td>11350.360054</td>\n",
       "      <td>3015.902504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>42211.13820</td>\n",
       "      <td>35603.824507</td>\n",
       "      <td>-6607.313693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>34828.65400</td>\n",
       "      <td>27902.502419</td>\n",
       "      <td>-6926.151581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188</th>\n",
       "      <td>21771.34230</td>\n",
       "      <td>32334.209245</td>\n",
       "      <td>10562.866945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>9095.06825</td>\n",
       "      <td>9092.519788</td>\n",
       "      <td>-2.548462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>11566.30055</td>\n",
       "      <td>16224.053528</td>\n",
       "      <td>4657.752978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>1880.48700</td>\n",
       "      <td>3861.767583</td>\n",
       "      <td>1981.280583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2457.21115</td>\n",
       "      <td>3274.369325</td>\n",
       "      <td>817.158175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>17043.34140</td>\n",
       "      <td>27065.591340</td>\n",
       "      <td>10022.249940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>26140.36030</td>\n",
       "      <td>9506.693466</td>\n",
       "      <td>-16633.666834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>402 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           actual    prediction      residual\n",
       "559    1646.42970   4610.315541   2963.885841\n",
       "1087  11353.22760  12887.893880   1534.666280\n",
       "1020   8798.59300  12573.948752   3775.355752\n",
       "460   10381.47870  13197.836626   2816.357926\n",
       "802    2103.08000    629.337182  -1473.742818\n",
       "298   38746.35510  32357.257584  -6389.097516\n",
       "481    9304.70190  12853.778438   3549.076538\n",
       "616   11658.11505  12273.662540    615.547490\n",
       "763    3070.80870   3865.164045    794.355345\n",
       "750   19539.24300  29904.111392  10364.868392\n",
       "48    12629.89670  11030.536184  -1599.360516\n",
       "547   11538.42100  17428.893541   5890.472541\n",
       "1143   6338.07560   8670.208104   2332.132504\n",
       "767    7050.64200   8357.459712   1306.817712\n",
       "194    1137.46970   3368.753659   2231.283959\n",
       "424    8968.33000  10316.585740   1348.255740\n",
       "3     21984.47061   3999.221358 -17985.249252\n",
       "785    6414.17800   6866.509328    452.331328\n",
       "443   28287.89766  14989.263965 -13298.633695\n",
       "921   13462.52000  14400.167009    937.647009\n",
       "315    9722.76950  12484.860025   2762.090525\n",
       "725   40932.42950  33255.453304  -7676.976196\n",
       "88     8026.66660   9177.111104   1150.444504\n",
       "310    8444.47400   8969.420175    524.946175\n",
       "471    2203.47185   3199.783106    996.311256\n",
       "726    6664.68595   8195.258443   1530.572493\n",
       "60     8606.21740   9355.744165    749.526765\n",
       "1280   8283.68070  10847.377942   2563.697242\n",
       "705    5375.03800   7694.604698   2319.566698\n",
       "101    3645.08940   4436.447849    791.358449\n",
       "...           ...           ...           ...\n",
       "1197   5699.83750   8873.734143   3173.896643\n",
       "520   25656.57526  10365.420802 -15291.154458\n",
       "408    6652.52880   5146.284716  -1506.244084\n",
       "403   10269.46000  12154.347446   1884.887446\n",
       "1084  15019.76005  14782.131446   -237.628604\n",
       "1276   2741.94800   4298.391463   1556.443463\n",
       "660    6435.62370  13086.510055   6650.886355\n",
       "1229  11938.25595  13045.515296   1107.259346\n",
       "774    7261.74100  10408.467573   3146.726573\n",
       "909   17496.30600  28136.555213  10640.249213\n",
       "1196  33307.55080  27176.138386  -6131.412414\n",
       "641   32787.45859  33165.632331    378.173741\n",
       "959   28468.91901  12621.577467 -15847.341543\n",
       "264   20462.99766  14665.580509  -5797.417151\n",
       "493   12574.04900  17154.057687   4580.008687\n",
       "625    3736.46470   4347.234024    610.769324\n",
       "1225   4795.65680   9509.419524   4713.762724\n",
       "927   12032.32600   9263.424639  -2768.901361\n",
       "53    37742.57570  31958.417709  -5784.157991\n",
       "1301  46718.16325  39026.197693  -7691.965557\n",
       "347    8334.45755  11350.360054   3015.902504\n",
       "1022  42211.13820  35603.824507  -6607.313693\n",
       "1291  34828.65400  27902.502419  -6926.151581\n",
       "1188  21771.34230  32334.209245  10562.866945\n",
       "764    9095.06825   9092.519788     -2.548462\n",
       "323   11566.30055  16224.053528   4657.752978\n",
       "1268   1880.48700   3861.767583   1981.280583\n",
       "134    2457.21115   3274.369325    817.158175\n",
       "1274  17043.34140  27065.591340  10022.249940\n",
       "876   26140.36030   9506.693466 -16633.666834\n",
       "\n",
       "[402 rows x 3 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = pd.DataFrame({\"actual\": y_test, \"prediction\": y_test_pred})\n",
    "summary[\"residual\"] = summary.prediction - summary.actual\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>3528.982731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bmi</td>\n",
       "      <td>1961.655208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>children</td>\n",
       "      <td>421.550164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gender_male</td>\n",
       "      <td>-141.359110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>smoker_yes</td>\n",
       "      <td>9733.786883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>region_northwest</td>\n",
       "      <td>-129.545886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>region_southeast</td>\n",
       "      <td>-414.541483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>region_southwest</td>\n",
       "      <td>-379.095344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature  coefficient\n",
       "0               age  3528.982731\n",
       "1               bmi  1961.655208\n",
       "2          children   421.550164\n",
       "3       gender_male  -141.359110\n",
       "4        smoker_yes  9733.786883\n",
       "5  region_northwest  -129.545886\n",
       "6  region_southeast  -414.541483\n",
       "7  region_southwest  -379.095344"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"feature\": X.columns, \"coefficient\": est.coef_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13276.698553898497"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4139.932064766016"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = np.mean(np.abs(summary.residual))\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36761456.35201327"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = np.mean(summary.residual ** 2)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6063.122656850451"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = np.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mean = np.mean(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2454442507366839"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sst = np.sum((y_train_mean - y_train) ** 2) # this measure is on baseline\n",
    "sse = np.sum((y_train_pred - y_train) ** 2) # this measure against the model\n",
    "sse/sst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7545557492633161"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2 = 1 - sse/sst\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.740598931692721"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_mean = np.mean(y_test)\n",
    "sst = np.sum((y_test_mean - y_test) ** 2) # this measure is on baseline\n",
    "sse = np.sum((y_test_pred - y_test) ** 2) # this measure against the model\n",
    "r2_test = 1 - sse/sst\n",
    "r2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 training: 0.754558730164975\n",
      "R2 test: 0.7406196610211806\n",
      "Rmse training: 6039.56519596171\n",
      "Rmse: testing 6062.8803930600625\n"
     ]
    }
   ],
   "source": [
    "print(\"R2 training:\", metrics.r2_score(y_train, y_train_pred))\n",
    "print(\"R2 test:\", metrics.r2_score(y_test, y_test_pred))\n",
    "\n",
    "print(\"Rmse training:\", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Rmse: testing\", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training: 0.6995515695067265\n",
      "R2 training: 0.7597949596783904\n",
      "R2 test: 0.7890454142619109\n",
      "Rmse training: 0.4509134476136262\n",
      "Rmse: testing 0.4212505908115039\n"
     ]
    }
   ],
   "source": [
    "# dependent variable/target varible/label\n",
    "label = \"charges\"\n",
    "\n",
    "# independepent variables/features/predictors\n",
    "X = df.drop(columns=[label])\n",
    "\n",
    "X[\"high_bmi\"] = np.where(X.bmi>30, 1, 0)\n",
    "X[\"high_age\"] = np.where(X.age>50, 1, 0)\n",
    "\n",
    "# vector for target variable\n",
    "y = np.log(df[label])\n",
    "\n",
    "# one hot encoding to conver categorical features into numeric\n",
    "# drop_first: remove first categorical feature ... it is redundant\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Creating trainnig and test sets\n",
    "# test_size is 30% of the whole\n",
    "# random_state: to reprduce the same combination of training and test records\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X.values, \n",
    "                                                                    \n",
    "                                                                    y, test_size = 0.3\n",
    "                                                        , random_state = 1)\n",
    "\n",
    "print(\"size of training:\", len(X_train)/len(X))\n",
    "\n",
    "# We want to calcualate z score for each column \n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# We calcualte mean and std dev for each column\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Calculating the z scores\n",
    "# purpose of z scoring is make mean = 0 and std = 1 for each column\n",
    "X_train_std = scaler.transform(X_train)\n",
    "\n",
    "# Displaying the mean and standard deviation of the stadandarized features\n",
    "pd.DataFrame(X_train_std).describe()\n",
    "\n",
    "# Applying the same transformation on the test data\n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "# building a regression model\n",
    "est = linear_model.LinearRegression()\n",
    "est.fit(X_train_std, y_train)\n",
    "\n",
    "# prediction on training and test data\n",
    "y_train_pred = est.predict(X_train_std)\n",
    "y_test_pred = est.predict(X_test_std)\n",
    "\n",
    "print(\"R2 training:\", metrics.r2_score(y_train, y_train_pred))\n",
    "print(\"R2 test:\", metrics.r2_score(y_test, y_test_pred))\n",
    "\n",
    "print(\"Rmse training:\", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Rmse: testing\", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training: 0.6995515695067265\n",
      "R2 training: 0.8371423307076078\n",
      "R2 test: 0.8747843201744885\n",
      "Rmse training: 0.37128400233098263\n",
      "Rmse: testing 0.32454535338893015\n"
     ]
    }
   ],
   "source": [
    "# dependent variable/target varible/label\n",
    "label = \"charges\"\n",
    "\n",
    "# independepent variables/features/predictors\n",
    "X = df.drop(columns=[label])\n",
    "\n",
    "X[\"high_bmi\"] = np.where(X.bmi>30, 1, 0)\n",
    "X[\"high_age\"] = np.where(X.age>50, 1, 0)\n",
    "\n",
    "# vector for target variable\n",
    "y = np.log(df[label])\n",
    "\n",
    "# one hot encoding to conver categorical features into numeric\n",
    "# drop_first: remove first categorical feature ... it is redundant\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Creating trainnig and test sets\n",
    "# test_size is 30% of the whole\n",
    "# random_state: to reprduce the same combination of training and test records\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X.values, \n",
    "                                                                    \n",
    "                                                                    y, test_size = 0.3\n",
    "                                                        , random_state = 1)\n",
    "\n",
    "print(\"size of training:\", len(X_train)/len(X))\n",
    "\n",
    "# We want to calcualate z score for each column \n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "poly = preprocessing.PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "scaler.fit(X_train_poly)\n",
    "# Calculating the z scores\n",
    "# purpose of z scoring is make mean = 0 and std = 1 for each column\n",
    "X_train_std = scaler.transform(X_train_poly)\n",
    "\n",
    "\n",
    "# Displaying the mean and standard deviation of the stadandarized features\n",
    "pd.DataFrame(X_train_std).describe()\n",
    "\n",
    "# Applying the same transformation on the test data\n",
    "X_test_std = scaler.transform(X_test_poly)\n",
    "\n",
    "# building a regression model\n",
    "est = linear_model.LinearRegression()\n",
    "est.fit(X_train_std, y_train)\n",
    "\n",
    "# prediction on training and test data\n",
    "y_train_pred = est.predict(X_train_std)\n",
    "y_test_pred = est.predict(X_test_std)\n",
    "\n",
    "print(\"R2 training:\", metrics.r2_score(y_train, y_train_pred))\n",
    "print(\"R2 test:\", metrics.r2_score(y_test, y_test_pred))\n",
    "\n",
    "print(\"Rmse training:\", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Rmse: testing\", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(936, 65)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  1.],\n",
       "       [ 1.,  2.,  3.,  1.,  2.,  3.,  4.,  6.,  9.],\n",
       "       [-1.,  2.,  1.,  1., -2., -1.,  4.,  2.,  1.],\n",
       "       [ 2.,  3.,  4.,  4.,  6.,  8.,  9., 12., 16.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([\n",
    "    [1, 0, 1],\n",
    "    [1, 2, 3],\n",
    "    [-1, 2, 1],\n",
    "    [2, 3, 4]\n",
    "])\n",
    "poly = preprocessing.PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly.fit_transform(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 training: 0.8371423307076078\n",
      "R2 test: 0.8747843201744885\n",
      "Rmse training: 0.37128400233098263\n",
      "Rmse: testing 0.32454535338893015\n"
     ]
    }
   ],
   "source": [
    "# dependent variable/target varible/label\n",
    "label = \"charges\"\n",
    "\n",
    "# independepent variables/features/predictors\n",
    "X = df.drop(columns=[label])\n",
    "\n",
    "X[\"high_bmi\"] = np.where(X.bmi>30, 1, 0)\n",
    "X[\"high_age\"] = np.where(X.age>50, 1, 0)\n",
    "\n",
    "# vector for target variable\n",
    "y = np.log(df[label])\n",
    "\n",
    "# one hot encoding to conver categorical features into numeric\n",
    "# drop_first: remove first value of a categorical feature ... it is redundant\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Creating trainnig and test sets\n",
    "# test_size is 30% of the whole\n",
    "# random_state: to reprduce the same combination of training and test records\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X.values, \n",
    "                                                                    \n",
    "                                                                    y, test_size = 0.3\n",
    "                                                        , random_state = 1)\n",
    "\n",
    "\n",
    "pipe = pipeline.Pipeline([\n",
    "    (\"poly\", preprocessing.PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    (\"scaler\", preprocessing.StandardScaler()),\n",
    "    (\"est\", linear_model.LinearRegression())\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# prediction on training and test data\n",
    "y_train_pred = pipe.predict(X_train)\n",
    "y_test_pred = pipe.predict(X_test)\n",
    "\n",
    "print(\"R2 training:\", metrics.r2_score(y_train, y_train_pred))\n",
    "print(\"R2 test:\", metrics.r2_score(y_test, y_test_pred))\n",
    "\n",
    "print(\"Rmse training:\", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Rmse: testing\", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
